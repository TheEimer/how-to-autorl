defaults:
  - override hydra/sweeper: optuna
  - override hydra/sweeper/sampler: random
  - override hydra/launcher: submitit_slurm

hydra:
  sweeper: 
    sampler:
      seed: ${seed}
    direction: minimize
    study_name: rs-idaac-${env_name}-${seed}
    n_trials: 16
    n_jobs: 100
    params: 
      lr: tag(log, interval(0.000001, 0.01))
      eps: tag(log, interval(0.000001, 0.01)) 
      alpha: interval(0.8, 0.9999)
      gae_lambda: interval(0.8, 0.9999)
      clip_param: interval(0.01, 0.9)
      use_nonlinear_clf: choice(True, False)
      entropy_coef: interval(0.0001, 0.9)
      value_loss_coef: interval(0.0001, 0.9)
      adv_loss_coef: interval(0.0001, 0.9)
      order_loss_coef: interval(0.0001, 0.9)
      max_grad_norm: interval(0.0001, 0.9)
      ppo_epoch: range(1, 10)
      value_freq: range(1, 10)
      value_epoch: range(1, 10)
  run:
    dir: tuning_output_rs/${algo}_${env_name}_seed_${seed}
  launcher:
    partition: learnfair
    gpus_per_task: 1
    mem_gb: 25
    timeout_min: 1720
  sweep:
    dir: tuning_output_rs/${algo}_${env_name}_seed_${seed}

save_dir: ./models/checkpoint.pt
load_dir: null
log_dir: ./logs
algo: idaac
seed: 0

env_name: coinrun
start_level: 0
num_levels: 200
distribution_mode: easy
num_env_steps: 25e6
num_processes: 64

use_best_hps: false
lr: 5e-4
eps: 1e-5
hidden_size: 256
log_interval: 10
clip_param: 0.2
num_mini_batch: 8
ppo_epoch: 3
num_steps: 256
max_grad_norm: 0.5
value_loss_coef: 0.5
entropy_coef: 0.01
gae_lambda: 0.95
gamma: 0.999
alpha: 0.99
no_cuda: false

clf_hidden_size: 4
order_loss_coef: 0.001
use_nonlinear_clf: false

adv_loss_coef: 0.25
value_freq: 1
value_epoch: 9