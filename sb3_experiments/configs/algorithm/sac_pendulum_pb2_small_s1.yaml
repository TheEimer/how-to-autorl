agent_class: SAC
total_timesteps: 1e6
n_eval_episodes: 5
policy_model: MlpPolicy
model_kwargs:
  learning_rate: [0.000457195597879538,0.000457195597879538,0.000457195597879538,0.000457195597879538,0.000457195597879538,0.000457195597879538,0.000457195597879538,0.000457195597879538,0.000457195597879538,0.000457195597879538,0.000457195597879538,0.000457195597879538,0.000457195597879538,0.000457195597879538,0.000457195597879538,0.000457195597879538,0.000457195597879538,0.000457195597879538,0.000457195597879538,0.00830823100090027,0.00830823100090027]
  batch_size: 256
  tau: [0.3267524388669776,0.3267524388669776,0.3267524388669776,0.3267524388669776,0.3267524388669776,0.3267524388669776,0.3267524388669776,0.3267524388669776,0.3267524388669776,0.3267524388669776,0.3267524388669776,0.3267524388669776,0.3267524388669776,0.3267524388669776,0.3267524388669776,0.3267524388669776,0.3267524388669776,0.3267524388669776,0.3267524388669776,0.2949670678710937,0.2949670678710937]
  gamma: 0.99
  learning_starts: 100
  buffer_size: 1000000
  train_freq: [808,808,808,808,808,808,808,808,808,808,808,808,808,808,808,808,808,808,808,791,791]
  gradient_steps: 1
  use_sde: False
  sde_sample_freq: -1