agent_class: SAC
total_timesteps: 1e6
n_eval_episodes: 5
policy_model: MlpPolicy
model_kwargs:
  learning_rate: [0.0021377260833978667,0.0021377260833978667,0.0021377260833978667,0.0021377260833978667,0.0021377260833978667,0.0021377260833978667,0.0021377260833978667,0.0021377260833978667,0.0021377260833978667,0.0021377260833978667,0.0021377260833978667,0.0021377260833978667,0.0021377260833978667,0.0021377260833978667,0.0021377260833978667,0.0021377260833978667,0.0021377260833978667,0.0021377260833978667,0.0021377260833978667,0.0004927293360233309,0.0004927293360233309]
  batch_size: [256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,512,512]
  tau: [0.3379860420227051,0.3379860420227051,0.3379860420227051,0.3379860420227051,0.3379860420227051,0.3379860420227051,0.3379860420227051,0.3379860420227051,0.3379860420227051,0.3379860420227051,0.3379860420227051,0.3379860420227051,0.3379860420227051,0.3379860420227051,0.3379860420227051,0.3379860420227051,0.3379860420227051,0.3379860420227051,0.3379860420227051,0.14392351347800442,0.14392351347800442]
  gamma: 0.99
  learning_starts: [4106,4106,4106,4106,4106,4106,4106,4106,4106,4106,4106,4106,4106,4106,4106,4106,4106,4106,4106,7851,7851]
  buffer_size: [50000000,50000000,50000000,50000000,50000000,50000000,50000000,50000000,50000000,50000000,50000000,50000000,50000000,50000000,50000000,50000000,50000000,50000000,50000000,17822432,17822432]
  train_freq: [612,612,612,612,612,612,612,612,612,612,612,612,612,612,612,612,612,612,612,1000,1000]
  gradient_steps: [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,8,8]
  use_sde: False
  sde_sample_freq: -1