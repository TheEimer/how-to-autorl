agent_class: SAC
total_timesteps: 1e6
n_eval_episodes: 5
policy_model: MlpPolicy
model_kwargs:
  learning_rate: [0.002835279554950579,0.002835279554950579,0.002835279554950579,0.002835279554950579,0.002835279554950579,0.002835279554950579,0.002835279554950579,0.002835279554950579,0.002835279554950579,0.002835279554950579,0.002835279554950579,0.002835279554950579,0.002835279554950579,0.002835279554950579,0.002835279554950579,0.002835279554950579,0.002835279554950579,0.002835279554950579,0.002835279554950579,0.00015080618382409797,0.00015080618382409797]
  batch_size: 256
  tau: [0.40378671386718745,0.40378671386718745,0.40378671386718745,0.40378671386718745,0.40378671386718745,0.40378671386718745,0.40378671386718745,0.40378671386718745,0.40378671386718745,0.40378671386718745,0.40378671386718745,0.40378671386718745,0.40378671386718745,0.40378671386718745,0.40378671386718745,0.40378671386718745,0.40378671386718745,0.40378671386718745,0.40378671386718745,0.8,0.8]
  gamma: 0.99
  learning_starts: 100
  buffer_size: 1000000
  train_freq: [398,398,398,398,398,398,398,398,398,398,398,398,398,398,398,398,398,398,398,677,677]
  gradient_steps: 1
  use_sde: False
  sde_sample_freq: -1