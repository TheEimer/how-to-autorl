agent_class: SAC
total_timesteps: 1e6
n_eval_episodes: 5
policy_model: MlpPolicy
model_kwargs:
  learning_rate: [9.789892110681986e-05,9.789892110681986e-05,9.789892110681986e-05,9.789892110681986e-05,9.789892110681986e-05,9.789892110681986e-05,9.789892110681986e-05,9.789892110681986e-05,9.789892110681986e-05,9.789892110681986e-05,9.789892110681986e-05,9.789892110681986e-05,9.789892110681986e-05,9.789892110681986e-05,9.789892110681986e-05,9.789892110681986e-05,9.789892110681986e-05,9.789892110681986e-05,9.789892110681986e-05,2.5511966681426177e-05,2.5511966681426177e-05]
  batch_size: 256
  tau: [0.012,0.012,0.012,0.012,0.012,0.012,0.012,0.012,0.012,0.012,0.012,0.012,0.012,0.012,0.012,0.012,0.012,0.012,0.012,0.5650187195616002,0.5650187195616002]
  gamma: 0.99
  learning_starts: 100
  buffer_size: 1000000
  train_freq: [350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,350,228,228]
  gradient_steps: 1
  use_sde: False
  sde_sample_freq: -1
