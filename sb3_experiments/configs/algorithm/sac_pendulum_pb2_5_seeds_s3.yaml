agent_class: SAC
total_timesteps: 1e6
n_eval_episodes: 5
policy_model: MlpPolicy
model_kwargs:
  learning_rate: [0.008115335367619995,0.008115335367619995,0.008115335367619995,0.008115335367619995,0.008115335367619995,0.008115335367619995,0.008115335367619995,0.008115335367619995,0.008115335367619995,0.008115335367619995,0.008115335367619995,0.008115335367619995,0.008115335367619995,0.008115335367619995,0.008115335367619995,0.008115335367619995,0.008115335367619995,0.008115335367619995,0.008115335367619995,1.0671030521392835e-05,1.0671030521392835e-05]
  batch_size: [512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,512,256,256]
  tau: [0.20603498816490173,0.20603498816490173,0.20603498816490173,0.20603498816490173,0.20603498816490173,0.20603498816490173,0.20603498816490173,0.20603498816490173,0.20603498816490173,0.20603498816490173,0.20603498816490173,0.20603498816490173,0.20603498816490173,0.20603498816490173,0.20603498816490173,0.20603498816490173,0.20603498816490173,0.20603498816490173,0.20603498816490173,0.2490729858987954,0.2490729858987954]
  gamma: 0.99
  learning_starts: [51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,7988,7988]
  buffer_size: [4546445,4546445,4546445,4546445,4546445,4546445,4546445,4546445,4546445,4546445,4546445,4546445,4546445,4546445,4546445,4546445,4546445,4546445,4546445,15344260,15344260]
  train_freq: [157,157,157,157,157,157,157,157,157,157,157,157,157,157,157,157,157,157,157,357,357]
  gradient_steps: [7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,3,3]
  use_sde: False
  sde_sample_freq: -1