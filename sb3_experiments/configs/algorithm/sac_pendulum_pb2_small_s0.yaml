agent_class: SAC
total_timesteps: 1e6
n_eval_episodes: 5
policy_model: MlpPolicy
model_kwargs:
  learning_rate: [0.003589908871062469,0.003589908871062469,0.003589908871062469,0.003589908871062469,0.003589908871062469,0.003589908871062469,0.003589908871062469,0.003589908871062469,0.003589908871062469,0.003589908871062469,0.003589908871062469,0.003589908871062469,0.003589908871062469,0.003589908871062469,0.003589908871062469,0.003589908871062469,0.003589908871062469,0.003589908871062469,0.003589908871062469,0.004435761128770121,0.004435761128770121]
  batch_size: 256
  tau: [0.021361994007068893,0.021361994007068893,0.021361994007068893,0.021361994007068893,0.021361994007068893,0.021361994007068893,0.021361994007068893,0.021361994007068893,0.021361994007068893,0.021361994007068893,0.021361994007068893,0.021361994007068893,0.021361994007068893,0.021361994007068893,0.021361994007068893,0.021361994007068893,0.021361994007068893,0.021361994007068893,0.021361994007068893,0.3159576374903707,0.3159576374903707]
  gamma: 0.99
  learning_starts: 100
  buffer_size: 1000000
  train_freq: [518,518,518,518,518,518,518,518,518,518,518,518,518,518,518,518,518,518,518,133,133]
  gradient_steps: 1
  use_sde: False
  sde_sample_freq: -1